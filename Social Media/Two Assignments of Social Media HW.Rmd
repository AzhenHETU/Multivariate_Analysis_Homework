---
title: "Social Media"
author: "Yuefei Chen"
date: "2024-03-29"
output:
  pdf_document: default
  html_document: default
---
# Loading the Dataset
In the dataset of "Social_media_cleaned.csv", the data is cleaned and every time stamp data has been transformed into numeric value data. These values are in the new columns "XXX_value". XXX means the Apps we use. Mean value of the data is also a kind of numeric data, which are shown in the last line. Additionally, N/A value has been replaced by 0.00. The point of my mean value of social media is in the line 23.  
```{r}
library(readr)
APP_data <- read_csv("Social Media_cleaned.csv")
APP_data <- APP_data[c(1:22), c(1:2, 4:5, 7:8, 10:11, 13:14, 16:17, 19:20, 22:23, 25:33)]
str(APP_data)
```

# Part I: Calculate the MVA distance of your social media usage and the class average

```{r}
MVA_data <- APP_data[c(1:22), c(3,5,7,9,11,13,15,17,19,20,21,25)]
cov_matrix <- cov(MVA_data)
mean_vector <- colMeans(MVA_data)
mahalanobis_distances <- mahalanobis(MVA_data, center = mean_vector, cov = cov_matrix)
mahalanobis_distances[22]
```

The MVA distance of my social media usage and the class average is 7.126339.

# Part II: Social Media Data - Midterm Prep
Summary and Takeaway
In the PCA model tells us these social media usage variables can be transformed into three components. Since after component 3 point, the curve decreasing becomes slow, and additionally, only first 3 components' variance are larger than 1, 3 principal components will be selected as PCA analysis model. When we test whether PCs will affect the "Tired waking up in morning". The p-value shows the hypothesis is not significant, so we cannot conclude these usage will affect classmates feeling when waking up in morning.
In this cluster analysis, since the dataset is not large and we do not know how many cluster we need. Hierarchical cluster analysis will be used in this model. These points will be clustered into two clusters. The cluster one is {9, 15, 20}. The cluster 2 is {1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22}
In this factor analysis model, four factors are ideal for the dataset. That is because from the scree plot there are significant decrease of the line before the factor is 4. After factor = 4, the change of the line is not significant. And after factor = 4, the data point is under the eigenvalue line. Additionally, from the chart of Very Simple Structure, factor = 4 line has good performance in fit. In component analysis, the factor loading between PC1 and Instagram, Snapchat, WhatsApp/Wechat are 0.9, 0.8, 0.6. The factor loading between PC2 and Twitter, OTT are 0.9, 0.7. The factor loading between PC3 and Linkedin, Youtube are 0.8, 0.8. The factor loading between PC4 and Reddit is 1.

## PCA Analysis

```{R}
APP_pca <- prcomp(MVA_data[,-c(9:12)],scale=TRUE)
APP_pca
summary(APP_pca)

(eigen_rent <- APP_pca$sdev^2)
names(eigen_rent) <- paste("PC",1:8,sep="")
eigen_rent
plot(eigen_rent, xlab = "Component number", ylab = "Component variance", type = "l", main = "Scree diagram")
plot(log(eigen_rent), xlab = "Component number",ylab = "log(Component variance)", type="l",main = "Log(eigenvalue) diagram")
```






```{R}
APP_pca_id <- cbind(APP_data[1:22,23],APP_pca$x)
APP_pca_id
var.test(PC1~APP_data$`Tired waking up in morning`,data=APP_pca_id)
var.test(PC2~APP_data$`Tired waking up in morning`,data=APP_pca_id)
var.test(PC3~APP_data$`Tired waking up in morning`,data=APP_pca_id)
var.test(PC4~APP_data$`Tired waking up in morning`,data=APP_pca_id)
var.test(PC5~APP_data$`Tired waking up in morning`,data=APP_pca_id)
var.test(PC6~APP_data$`Tired waking up in morning`,data=APP_pca_id)
var.test(PC7~APP_data$`Tired waking up in morning`,data=APP_pca_id)
var.test(PC8~APP_data$`Tired waking up in morning`,data=APP_pca_id)
pairs(APP_pca$x[,1:8], ylim = c(-6,4),xlim = c(-6,4),panel=function(x,y,...){text(x,y,APP_pca_id$`Tired waking up in morning`)})
```


## Cluster Analysis

```{R}
library(cluster)
library(readr)
library(factoextra)
library(magrittr)
library(NbClust)
matstd.APP <- scale(MVA_data)
dist.APP <- dist(matstd.APP, method="euclidean")
clusAPP.nn <- hclust(dist.APP, method = "single")
plot(as.dendrogram(clusAPP.nn),ylab="Distance between classmates",ylim=c(0,6),main="Dendrogram. social media usage")
plot(as.dendrogram(clusAPP.nn), xlab= "Distance between classmates", xlim=c(6,0), horiz = TRUE,main="Dendrogram. social media usage")
(agn.APP <- agnes(MVA_data, metric="euclidean", stand=TRUE, method = "single"))
agn.APP$merge
plot(as.dendrogram(agn.APP), xlab= "Distance between Countries",xlim=c(8,0), horiz = TRUE,main="Dendrogram \n social media usage")




plot(agn.APP, which.plots=1)
plot(agn.APP, which.plots=2)
plot(agn.APP, which.plots=3)
```
#factor analysis

```{R}
library(psych)
fit.pc <- principal(MVA_data[,-c(9:12)], nfactors=4, rotate="varimax")
fit.pc
round(fit.pc$values, 3)
fit.pc$loadings
fa.parallel(MVA_data)
fa.plot(fit.pc)
fa.diagram(fit.pc)
vss(MVA_data)
```








```{R}
(eigen_APP_vars <- round(APP_pca$sdev^2,3))
names(eigen_APP_vars) <- paste("PC",1:8,sep="")
sumlambdas <- sum(eigen_APP_vars)
propvar <- round(eigen_APP_vars/sumlambdas,2)
cumvar_APP_vars <- cumsum(propvar)
matlambdas <- rbind(eigen_APP_vars,propvar,cumvar_APP_vars)
rownames(matlambdas) <- c("Eigenvalues","Prop. variance","Cum. prop. variance")
eigvec.emp <- APP_pca$rotation
pcafactors.emp <- eigvec.emp[,1:2]
unrot.fact.emp <- sweep(pcafactors.emp,MARGIN=2,APP_pca$sdev[1:2],`*`)
communalities.emp <- rowSums(unrot.fact.emp^2)
communalities.emp
rot.fact.emp <- varimax(unrot.fact.emp)
rot.fact.emp
fact.load.emp <- rot.fact.emp$loadings[1:6,1:2]
fact.load.emp
scale.emp <- scale(MVA_data[,-c(9:12)])
scale.emp
```