---
title: "HW5_Yuefei_Chen_Cluster_Analysis"
author: "Yuefei Chen"
date: "2024-03-06"
output:
  pdf_document: default
  html_document: default
---
## Question 1, for each model, decide the optimal number of clusters and explain why.
### ANS: According to the result of the plot about hierarchical clustering models and non-hierarchical models, the optimal number of clusters is 2 for both models. That is because in the hierachical clustering models and dendrogram, we can find one cluster has most rooms memberships which have close distances and the other one contains outlier points. In the non-hierachical clustering models, there is a significantly decrease in variance from 2 clusters to 3 clusters. Thus, 2 clusters is a optimal choice for the non-hierarchical model.

## Question 2, show the membership for each cluster.
### ANS: 
Hierarchical clustering models: 
cluster 1: Room 10, Room 12, Room 17
cluster 2: Room 1, Room 2, Room 3, Room 4, Room 5, Room 6, Room 7, Room 8, Room 9, Room 11, Room 13, Room 14,
Room 15, Room 16, Room 18, Room 19, Room 20

Non-hierarchical clustering models:
cluster 1: Room1, Room5, Room6, Room9, Room10, Room12, Room19
cluster 2: Room2, Room3, Room4, Room7, Room8, Room11, Room13, Room14, Room15, Room16, Room17, Room18, Room20 

## Question 3
### ANS: [Click to Visualization](#visualization)

#### Hierarchical Clustering Models

```{R}
library(cluster)
library(readr)
library(factoextra)
library(magrittr)
library(NbClust)

Rent <- read.csv("Dataset/Rent_House_random_20_cluster.csv",row.names=1)

attach(Rent)
dim(Rent)
str(Rent)
str(Rent)
# Hirerarchic cluster analysis, Nearest-neighbor

# Standardizing the data with scale()
matstd.Rent <- scale(Rent)
# Creating a (Euclidean) distance matrix of the standardized data
dist.Rent <- dist(matstd.Rent, method="euclidean")
# Invoking hclust command (cluster analysis by single linkage method)
clusRent.nn <- hclust(dist.Rent, method = "single")

plot(as.dendrogram(clusRent.nn),ylab="Distance between countries",ylim=c(0,6),
     main="Dendrogram. Rent Room Prices")

plot(as.dendrogram(clusRent.nn), xlab= "Distance between countries", xlim=c(6,0),
     horiz = TRUE,main="Dendrogram. Rent Room Prices")
# We will use agnes function as it allows us to select option for data standardization, the distance measure and clustering algorithm in one single function
(agn.Rent <- agnes(Rent, metric="euclidean", stand=TRUE, method = "single"))
#View(agn.employ)

#  Description of cluster merging
agn.Rent$merge
#Dendogram
plot(as.dendrogram(agn.Rent), xlab= "Distance between Countries",xlim=c(8,0),
     horiz = TRUE,main="Dendrogram \n Rent Room Prices")
#Interactive Plots
#plot(agn.employ,ask=TRUE)
plot(agn.Rent, which.plots=1)
plot(agn.Rent, which.plots=2)
plot(agn.Rent, which.plots=3)
```

#### Non-hierarchy Clustering Models

```{R}
# K-Means Clustering
matstd.Rent <- scale(Rent)
# K-means, k=2, 3, 4, 5, 6
# Centers (k's) are numbers thus, 10 random sets are chosen
(kmeans2.Rent <- kmeans(matstd.Rent,2,nstart = 10))
# Computing the percentage of variation accounted for. Two clusters
perc.var.2 <- round(100*(1 - kmeans2.Rent$betweenss/kmeans2.Rent$totss),1)
names(perc.var.2) <- "Perc. 2 clus"
perc.var.2
# Computing the percentage of variation accounted for. Three clusters
(kmeans3.Rent <- kmeans(matstd.Rent,3,nstart = 10))
perc.var.3 <- round(100*(1 - kmeans3.Rent$betweenss/kmeans3.Rent$totss),1)
names(perc.var.3) <- "Perc. 3 clus"
perc.var.3
# Computing the percentage of variation accounted for. Four clusters
(kmeans4.Rent <- kmeans(matstd.Rent,4,nstart = 10))
perc.var.4 <- round(100*(1 - kmeans4.Rent$betweenss/kmeans4.Rent$totss),1)
names(perc.var.4) <- "Perc. 4 clus"
perc.var.4
# Computing the percentage of variation accounted for. Five clusters
(kmeans5.Rent <- kmeans(matstd.Rent,5,nstart = 10))
perc.var.5 <- round(100*(1 - kmeans5.Rent$betweenss/kmeans5.Rent$totss),1)
names(perc.var.5) <- "Perc. 5 clus"
perc.var.5
(kmeans6.Rent <- kmeans(matstd.Rent,6,nstart = 10))
# Computing the percentage of variation accounted for. Six clusters
perc.var.6 <- round(100*(1 - kmeans6.Rent$betweenss/kmeans6.Rent$totss),1)
names(perc.var.6) <- "Perc. 6 clus"
perc.var.6
attributes(perc.var.6)
Variance_List <- c(perc.var.2,perc.var.3,perc.var.4,perc.var.5,perc.var.6)
Variance_List
plot(Variance_List)
kmeans2.Rent$cluster
```











## visualization
```{R}
# use PC1 and PC2
rent_pca <- prcomp(Rent, scale = TRUE)
rent.nbclust <- rent_pca$x[,c(1,2)] %>% scale() %>% NbClust(distance = "euclidean", min.nc = 2, max.nc = 10, method = "complete", index = "all")

rent.hc <- rent_pca$x[,c(1,2)] %>% scale() %>%
  eclust("hclust", k = 2, graph = FALSE)

fviz_dend(rent.hc, palette = "jco",
          rect = TRUE, show_labels = FALSE)

#Inspect the silhouette plot:
fviz_silhouette(rent.hc)

```